diff --git a/CMakeLists.txt b/CMakeLists.txt
index fa2e935c..a23c73c8 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -109,8 +109,11 @@ use_cxx11()
 
 if(CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
     #required by butil/crc32.cc to boost performance for 10x
-    if(NOT (CMAKE_CXX_COMPILER_VERSION VERSION_LESS 4.4))
+    if((CMAKE_SYSTEM_PROCESSOR MATCHES "(x86)|(X86)|(amd64)|(AMD64)") AND NOT (CMAKE_CXX_COMPILER_VERSION VERSION_LESS 4.4))
         set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -msse4 -msse4.2")
+    elseif((CMAKE_SYSTEM_PROCESSOR MATCHES "aarch64"))
+        # segmentation fault in libcontext
+        set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fno-gcse")
     endif()
     if(NOT (CMAKE_CXX_COMPILER_VERSION VERSION_LESS 7.0))
         set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Wno-aligned-new")
diff --git a/src/bthread/context.cpp b/src/bthread/context.cpp
index 5e02f729..0a6d90bc 100644
--- a/src/bthread/context.cpp
+++ b/src/bthread/context.cpp
@@ -562,7 +562,8 @@ __asm (
 "    @ and as first arg in context function\n"
 "    mov  a1, a3\n"
 "    @ restore v1-V8,LR,PC\n"
-"    pop {v1-v8,lr,pc}\n"
+"    pop {v1-v8,lr}\n"
+"    pop {pc}\n"
 ".size bthread_jump_fcontext,.-bthread_jump_fcontext\n"
 "@ Mark that we don't need executable stack.\n"
 ".section .note.GNU-stack,\"\",%progbits\n"
@@ -600,3 +601,106 @@ __asm (
 );
 
 #endif
+
+#if defined(BTHREAD_CONTEXT_PLATFORM_linux_arm64) && defined(BTHREAD_CONTEXT_COMPILER_gcc)
+__asm (
+".cpu    generic+fp+simd\n"
+".text\n"
+".align  2\n"
+".global bthread_jump_fcontext\n"
+".type   bthread_jump_fcontext, %function\n"
+"bthread_jump_fcontext:\n"
+"    # prepare stack for GP + FPU\n"
+"    sub  sp, sp, #0xb0\n"
+"# Because gcc may save integer registers in fp registers across a\n"
+"# function call we cannot skip saving the fp registers.\n"
+"#\n"
+"# Do not reinstate this test unless you fully understand what you\n"
+"# are doing.\n"
+"#\n"
+"#    # test if fpu env should be preserved\n"
+"#    cmp  w3, #0\n"
+"#    b.eq  1f\n"
+"    # save d8 - d15\n"
+"    stp  d8,  d9,  [sp, #0x00]\n"
+"    stp  d10, d11, [sp, #0x10]\n"
+"    stp  d12, d13, [sp, #0x20]\n"
+"    stp  d14, d15, [sp, #0x30]\n"
+"1:\n"
+"    # save x19-x30\n"
+"    stp  x19, x20, [sp, #0x40]\n"
+"    stp  x21, x22, [sp, #0x50]\n"
+"    stp  x23, x24, [sp, #0x60]\n"
+"    stp  x25, x26, [sp, #0x70]\n"
+"    stp  x27, x28, [sp, #0x80]\n"
+"    stp  x29, x30, [sp, #0x90]\n"
+"    # save LR as PC\n"
+"    str  x30, [sp, #0xa0]\n"
+"    # store RSP (pointing to context-data) in first argument (x0).\n"
+"    # STR cannot have sp as a target register\n"
+"    mov  x4, sp\n"
+"    str  x4, [x0]\n"
+"    # restore RSP (pointing to context-data) from A2 (x1)\n"
+"    mov  sp, x1\n"
+"#    # test if fpu env should be preserved\n"
+"#    cmp  w3, #0\n"
+"#    b.eq  2f\n"
+"    # load d8 - d15\n"
+"    ldp  d8,  d9,  [sp, #0x00]\n"
+"    ldp  d10, d11, [sp, #0x10]\n"
+"    ldp  d12, d13, [sp, #0x20]\n"
+"    ldp  d14, d15, [sp, #0x30]\n"
+"2:\n"
+"    # load x19-x30\n"
+"    ldp  x19, x20, [sp, #0x40]\n"
+"    ldp  x21, x22, [sp, #0x50]\n"
+"    ldp  x23, x24, [sp, #0x60]\n"
+"    ldp  x25, x26, [sp, #0x70]\n"
+"    ldp  x27, x28, [sp, #0x80]\n"
+"    ldp  x29, x30, [sp, #0x90]\n"
+"    # use third arg as return value after jump\n"
+"    # and as first arg in context function\n"
+"    mov  x0, x2\n"
+"    # load pc\n"
+"    ldr  x4, [sp, #0xa0]\n"
+"    # restore stack from GP + FPU\n"
+"    add  sp, sp, #0xb0\n"
+"    ret x4\n"
+".size   bthread_jump_fcontext,.-bthread_jump_fcontext\n"
+"# Mark that we don't need executable stack.\n"
+".section .note.GNU-stack,\"\",%progbits\n"
+);
+
+#endif
+
+#if defined(BTHREAD_CONTEXT_PLATFORM_linux_arm64) && defined(BTHREAD_CONTEXT_COMPILER_gcc)
+__asm (
+".cpu    generic+fp+simd\n"
+".text\n"
+".align  2\n"
+".global bthread_make_fcontext\n"
+".type   bthread_make_fcontext, %function\n"
+"bthread_make_fcontext:\n"
+"    # shift address in x0 (allocated stack) to lower 16 byte boundary\n"
+"    and x0, x0, ~0xF\n"
+"    # reserve space for context-data on context-stack\n"
+"    sub  x0, x0, #0xb0\n"
+"    # third arg of bthread_make_fcontext() == address of context-function\n"
+"    # store address as a PC to jump in\n"
+"    str  x2, [x0, #0xa0]\n"
+"    # save address of finish as return-address for context-function\n"
+"    # will be entered after context-function returns (LR register)\n"
+"    adr  x1, finish\n"
+"    str  x1, [x0, #0x98]\n"
+"    ret  x30 \n"
+"finish:\n"
+"    # exit code is zero\n"
+"    mov  x0, #0\n"
+"    # exit application\n"
+"    bl  _exit\n"
+".size   bthread_make_fcontext,.-bthread_make_fcontext\n"
+"# Mark that we don't need executable stack.\n"
+".section .note.GNU-stack,\"\",%progbits\n"
+);
+
+#endif
diff --git a/src/bthread/context.h b/src/bthread/context.h
index 5fe07e46..19bda216 100644
--- a/src/bthread/context.h
+++ b/src/bthread/context.h
@@ -30,6 +30,9 @@
 	#elif __arm__
 	    #define BTHREAD_CONTEXT_PLATFORM_linux_arm32
 	    #define BTHREAD_CONTEXT_CALL_CONVENTION
+	#elif __aarch64__
+	    #define BTHREAD_CONTEXT_PLATFORM_linux_arm64
+	    #define BTHREAD_CONTEXT_CALL_CONVENTION
 	#endif
 
     #elif defined(__MINGW32__) || defined (__MINGW64__)
diff --git a/src/bthread/processor.h b/src/bthread/processor.h
index 001e95c9..13cf5d51 100644
--- a/src/bthread/processor.h
+++ b/src/bthread/processor.h
@@ -19,9 +19,15 @@
 #ifndef BTHREAD_PROCESSOR_H
 #define BTHREAD_PROCESSOR_H
 
+#include "butil/build_config.h"
+
 // Pause instruction to prevent excess processor bus usage, only works in GCC
 # ifndef cpu_relax
+#if defined(ARCH_CPU_ARM_FAMILY)
+# define cpu_relax() asm volatile("yield\n": : :"memory")
+#else
 # define cpu_relax() asm volatile("pause\n": : :"memory")
+#endif
 # endif
 
 // Compile read-write barrier
diff --git a/src/butil/containers/case_ignored_flat_map.cpp b/src/butil/containers/case_ignored_flat_map.cpp
index b4c14699..5467fdb6 100644
--- a/src/butil/containers/case_ignored_flat_map.cpp
+++ b/src/butil/containers/case_ignored_flat_map.cpp
@@ -17,7 +17,7 @@
 
 namespace butil {
 
-static const char g_tolower_map_base[] = {
+static const signed char g_tolower_map_base[] = {
     -128, -127, -126, -125, -124, -123, -122, -121, -120,
     -119, -118, -117, -116, -115, -114, -113, -112, -111, -110,
     -109, -108, -107, -106, -105, -104, -103, -102, -101, -100,
@@ -46,6 +46,6 @@ static const char g_tolower_map_base[] = {
     120, 121, 122, 123, 124, 125, 126, 127
 };
 
-extern const char* const g_tolower_map = g_tolower_map_base + 128;
+extern const signed char* const g_tolower_map = g_tolower_map_base + 128;
 
 } // namespace butil
diff --git a/src/butil/containers/case_ignored_flat_map.h b/src/butil/containers/case_ignored_flat_map.h
index 0a8f264c..fd7b7f5e 100644
--- a/src/butil/containers/case_ignored_flat_map.h
+++ b/src/butil/containers/case_ignored_flat_map.h
@@ -25,7 +25,7 @@ namespace butil {
 // NOTE: Using ascii_tolower instead of ::tolower shortens 150ns in
 // FlatMapTest.perf_small_string_map (with -O2 added, -O0 by default)
 inline char ascii_tolower(char c) {
-    extern const char* const g_tolower_map;
+    extern const signed char* const g_tolower_map;
     return g_tolower_map[(int)c];
 }
 
diff --git a/src/butil/third_party/snappy/snappy-internal.h b/src/butil/third_party/snappy/snappy-internal.h
index b6831fe9..3822a99b 100644
--- a/src/butil/third_party/snappy/snappy-internal.h
+++ b/src/butil/third_party/snappy/snappy-internal.h
@@ -132,7 +132,7 @@ static inline int FindMatchLength(const char* s1,
         matched += 4;
     }
     if (LittleEndian::IsLittleEndian() && s2 <= s2_limit - 4) {
-        uint32 x = UNALIGNED_LOAD32(s2) ^ UNALIGNED_LOAD32(s1 + matched);
+        uint32_t x = UNALIGNED_LOAD32(s2) ^ UNALIGNED_LOAD32(s1 + matched);
         int matching_bits = Bits::FindLSBSetNonZero(x);
         matched += matching_bits >> 3;
     } else {
diff --git a/src/butil/third_party/snappy/snappy-stubs-internal.h b/src/butil/third_party/snappy/snappy-stubs-internal.h
index bf5e93e2..e94a9c73 100644
--- a/src/butil/third_party/snappy/snappy-stubs-internal.h
+++ b/src/butil/third_party/snappy/snappy-stubs-internal.h
@@ -114,13 +114,13 @@ namespace snappy {
 // See if that would be more efficient on platforms supporting it,
 // at least for copies.
 
-inline uint64_tUNALIGNED_LOAD64(const void *p) {
-    uint64_tt;
+inline uint64_t UNALIGNED_LOAD64(const void *p) {
+    uint64_t t;
     memcpy(&t, p, sizeof t);
     return t;
 }
 
-inline void UNALIGNED_STORE64(void *p, uint64_tv) {
+inline void UNALIGNED_STORE64(void *p, uint64_t v) {
     memcpy(p, &v, sizeof v);
 }
 
@@ -141,8 +141,8 @@ inline uint32_t UNALIGNED_LOAD32(const void *p) {
     return t;
 }
 
-inline uint64_tUNALIGNED_LOAD64(const void *p) {
-    uint64_tt;
+inline uint64_t UNALIGNED_LOAD64(const void *p) {
+    uint64_t t;
     memcpy(&t, p, sizeof t);
     return t;
 }
@@ -155,7 +155,7 @@ inline void UNALIGNED_STORE32(void *p, uint32_t v) {
     memcpy(p, &v, sizeof v);
 }
 
-inline void UNALIGNED_STORE64(void *p, uint64_tv) {
+inline void UNALIGNED_STORE64(void *p, uint64_t v) {
     memcpy(p, &v, sizeof v);
 }
 
