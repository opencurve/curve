#
# mds options
#
mds.listen.addr=127.0.0.1:6700  #__CURVEADM_TEMPLATE__ ${service_addr}:${service_port} __CURVEADM_TEMPLATE__   __ANSIBLE_TEMPLATE__ {{ curvefs_mds_listen_host }}:{{ curvefs_mds_listen_port }} __ANSIBLE_TEMPLATE__
# dummy server port
mds.dummy.port=7700  # __CURVEADM_TEMPLATE__ ${service_dummy_port} __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ {{ curvefs_mds_listen_dummy_port }} __ANSIBLE_TEMPLATE__
mds.common.logDir=/tmp/curvefs/mds  # __CURVEADM_TEMPLATE__ ${prefix}/logs __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ /tmp/{{ inventory_hostname }}/curvefs/mds __ANSIBLE_TEMPLATE__
#
# space options
#
space.addr=127.0.0.1:19999  # __ANSIBLE_TEMPLATE__ {{ groups.space | join_peer(hostvars, "space_listen_port") }} __ANSIBLE_TEMPLATE__
space.rpcTimeoutMs=500

#
# metaserver options
#
metaserver.addr=127.0.0.1:6701  # __CURVEADM_TEMPLATE__ ${cluster_mds_addr} __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ {{ groups.metaserver | join_peer(hostvars, "metaserver_listen_port") }} __ANSIBLE_TEMPLATE__
metaserver.rpcTimeoutMs=5000
metaserver.rpcRertyTimes=3
metaserver.rpcRetryIntervalUs=1000000

#
# etcd options
#
# etcd listen address
etcd.endpoint=127.0.0.1:2379  # __CURVEADM_TEMPLATE__ ${cluster_etcd_addr} __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ {{ groups.etcd | join_peer(hostvars, "etcd_listen_client_port") }} __ANSIBLE_TEMPLATE__
# timeout for establishing a connection
etcd.dailtimeoutMs=5000
# timeout for the operation
etcd.operation.timeoutMs=5000
# number of times a failed operation can be retried
etcd.retry.times=3

#
# leader election options
#
leader.sessionInterSec=5
leader.electionTimeoutMs=0

#
# topology config
#
# time interval flush data to db
mds.topology.TopologyUpdateToRepoSec=60
# the policy of choose pool 0:Random, 1:Weight
mds.topology.ChoosePoolPolicy=0
# partition number in each copyset 2^8
mds.topology.PartitionNumberInCopyset=256
# id number in each partition 2^24 [0, 2^24-1]
mds.topology.IdNumberInPartition=16777216
# create copyset number at a time
mds.topology.CreateCopysetNumber=10
# default create partition number 3
mds.topology.CreatePartitionNumber=3
# Topology update metric interval
mds.topology.UpdateMetricIntervalSec=60

#
# heartbeat config
#
# heartbeat interval between metaserver and mds
mds.heartbeat.intervalMs=10000
# heartbeat miss time between metaserver and mds
mds.heartbeat.misstimeoutMs=30000
# heartbeat offline time between metaserver and mds
mds.heartbeat.offlinetimeoutMs=1800000
# After mds is started, a certain time delay starts to guide the metaserver to delete data
# default is 20 min
mds.heartbeat.clean_follower_afterMs=1200000

#
# schedule config
#
# recoverScheduler switch
mds.enable.recover.scheduler=true
# RecoverScheduler round interval, the unit is second
mds.recover.scheduler.intervalSec=5
# Concurrency of operator on each metaserver
mds.schduler.operator.concurrent=1
# transfer leader timeout, after the timeout, mds removes the operator from the memory
mds.schduler.transfer.limitSec=60
# remove a replica timeout, after the timeout, mds removes the operator from the memory
mds.scheduler.remove.limitSec=300
# add a replica timeout, after the timeout, mds removes the operator from the memory
mds.scheduler.add.limitSec=1800
# change the replica timeout, after the timeout, mds removes the operator from the memory
mds.scheduler.change.limitSec=1800
# metaserver can be used as target leader only after starting coolingTimeSec_, the unit is second
mds.scheduler.metaserver.cooling.timeSec=1800

#
# fsmananger config
#
# the backend thread check whether fs is able to delete,
# check partition of deleting fs is deleting
mds.fsmanager.backEndThreadRunInterSec=10

#### s3
# the max size that fuse send
s3.fuseMaxSize=131072
s3.pagesize=65536
# prefetch blocks that disk cache use
s3.prefetchBlocks=1
# prefetch threads
s3.prefetchExecQueueNum=1
# start sleep when mem cache use ratio is greater than nearfullRatio,
# sleep time increase follow with mem cache use raito, baseSleepUs is baseline.
s3.nearfullRatio=70
s3.baseSleepUs=500

# TODO(huyao): use more meaningfull name
# background thread schedule time
s3.intervalSec=3
# data cache flush wait time
s3.flushIntervalSec=5
s3.writeCacheMaxByte=838860800
s3.readCacheMaxByte=209715200
# http = 0, https = 1
s3.http_scheme=0
s3.verify_SSL=False
s3.max_connections=32
s3.connect_timeout=60000
s3.request_timeout=10000
# Off = 0,Fatal = 1,Error = 2,Warn = 3,Info = 4,Debug = 5,Trace = 6
s3.loglevel=4
s3.logPrefix=/data/logs/curvefs/aws_  # __CURVEADM_TEMPLATE__ /curvefs/client/logs/aws_ __CURVEADM_TEMPLATE__
s3.async_thread_num=30
# limit all inflight async requests' bytes, |0| means not limited
s3.max_async_request_inflight_bytes=104857600
# throttle
s3.throttle.iopsTotalLimit=0
s3.throttle.iopsReadLimit=0
s3.throttle.iopsWriteLimit=0
s3.throttle.bpsTotalMB=0
s3.throttle.bpsReadMB=0
s3.throttle.bpsWriteMB=0
