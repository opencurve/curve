#
# mds options
#
mds.listen.addr=127.0.0.1:6700  #__CURVEADM_TEMPLATE__ ${service_addr}:${service_port} __CURVEADM_TEMPLATE__   __ANSIBLE_TEMPLATE__ {{ curvefs_mds_listen_host }}:{{ curvefs_mds_listen_port }} __ANSIBLE_TEMPLATE__
# dummy server port
mds.dummy.port=7700  # __CURVEADM_TEMPLATE__ ${service_dummy_port} __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ {{ curvefs_mds_listen_dummy_port }} __ANSIBLE_TEMPLATE__
mds.common.logDir=/tmp/curvefs/mds  # __CURVEADM_TEMPLATE__ ${prefix}/logs __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ /tmp/{{ inventory_hostname }}/curvefs/mds __ANSIBLE_TEMPLATE__
#
# space options
#
space.addr=127.0.0.1:19999  # __ANSIBLE_TEMPLATE__ {{ groups.space | join_peer(hostvars, "space_listen_port") }} __ANSIBLE_TEMPLATE__
space.rpcTimeoutMs=500

#
# metaserver options
#
metaserver.addr=127.0.0.1:6701  # __CURVEADM_TEMPLATE__ ${cluster_mds_addr} __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ {{ groups.metaserver | join_peer(hostvars, "metaserver_listen_port") }} __ANSIBLE_TEMPLATE__
metaserver.rpcTimeoutMs=5000
metaserver.rpcRertyTimes=3
metaserver.rpcRetryIntervalUs=1000000

#
# etcd options
#
# etcd listen address
etcd.endpoint=127.0.0.1:2379  # __CURVEADM_TEMPLATE__ ${cluster_etcd_addr} __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ {{ groups.etcd | join_peer(hostvars, "etcd_listen_client_port") }} __ANSIBLE_TEMPLATE__
# timeout for establishing a connection
etcd.dailtimeoutMs=5000
# timeout for the operation
etcd.operation.timeoutMs=5000
# number of times a failed operation can be retried
etcd.retry.times=3

#
# leader election options
#
leader.sessionInterSec=5
leader.electionTimeoutMs=0

#
# topology config
#
# time interval flush data to db
mds.topology.TopologyUpdateToRepoSec=60
# the policy of choose pool 0:Random, 1:Weight
mds.topology.ChoosePoolPolicy=0
# max partition number in copyset 2^8
mds.topology.MaxPartitionNumberInCopyset=256
# id number in each partition 2^24 [0, 2^24-1]
mds.topology.IdNumberInPartition=16777216
# initial copyset number in cluster
mds.topology.InitialCopysetNumber=10
# min avaiable copyset num in cluster
mds.topology.MinAvailableCopysetNum=10
# default create partition number 3
mds.topology.CreatePartitionNumber=3
# max copyset num in metaserver
mds.topology.MaxCopysetNumInMetaserver=100
# Topology update metric interval
mds.topology.UpdateMetricIntervalSec=60

#
# heartbeat config
#
# heartbeat interval between metaserver and mds
mds.heartbeat.intervalMs=10000
# heartbeat miss time between metaserver and mds
mds.heartbeat.misstimeoutMs=30000
# heartbeat offline time between metaserver and mds
mds.heartbeat.offlinetimeoutMs=1800000
# After mds is started, a certain time delay starts to guide the metaserver to delete data
# default is 20 min
mds.heartbeat.clean_follower_afterMs=1200000

#
# schedule config
#
# recoverScheduler switch
mds.enable.recover.scheduler=true
# copysetScheduler switch
mds.enable.copyset.scheduler=true
# RecoverScheduler round interval, the unit is second
mds.recover.scheduler.intervalSec=5
# copysetScheduler round interval, the unit is second
mds.copyset.scheduler.intervalSec=5
# the percentage difference for copysetScheduler to
# determine whether resource balancing is required
# based on the difference in resource usage percent, default is 30%
mds.copyset.scheduler.balanceRatioPercent=30
# Concurrency of operator on each metaserver
mds.schduler.operator.concurrent=1
# transfer leader timeout, after the timeout, mds removes the operator from the memory
mds.schduler.transfer.limitSec=60
# remove a replica timeout, after the timeout, mds removes the operator from the memory
mds.scheduler.remove.limitSec=300
# add a replica timeout, after the timeout, mds removes the operator from the memory
mds.scheduler.add.limitSec=1800
# change the replica timeout, after the timeout, mds removes the operator from the memory
mds.scheduler.change.limitSec=1800
# metaserver can be used as target leader only after starting coolingTimeSec_, the unit is second
mds.scheduler.metaserver.cooling.timeSec=1800

#
# fsmananger config
#
# the backend thread check whether fs is able to delete,
# check partition of deleting fs is deleting
mds.fsmanager.backEndThreadRunInterSec=10
# number of threads that load space info of volume
mds.fsmanager.reloadSpaceConcurrency=10

#### s3
# TODO(huyao): use more meaningfull name
# http = 0, https = 1
s3.http_scheme=0
s3.verify_SSL=False
s3.max_connections=32
s3.connect_timeout=60000
s3.request_timeout=10000
# Off = 0,Fatal = 1,Error = 2,Warn = 3,Info = 4,Debug = 5,Trace = 6
s3.loglevel=4
s3.logPrefix=/data/logs/curvefs/aws_  # __CURVEADM_TEMPLATE__ /curvefs/client/logs/aws_ __CURVEADM_TEMPLATE__
s3.async_thread_num=30
# limit all inflight async requests' bytes, |0| means not limited
s3.max_async_request_inflight_bytes=104857600
# throttle
s3.throttle.iopsTotalLimit=0
s3.throttle.iopsReadLimit=0
s3.throttle.iopsWriteLimit=0
s3.throttle.bpsTotalMB=0
s3.throttle.bpsReadMB=0
s3.throttle.bpsWriteMB=0
s3.useVirtualAddressing=false
