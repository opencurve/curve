#
# mds options
#
mds.listen.addr=127.0.0.1:6700  #__CURVEADM_TEMPLATE__ ${service_addr}:${service_port} __CURVEADM_TEMPLATE__   __ANSIBLE_TEMPLATE__ {{ curvefs_mds_listen_host }}:{{ curvefs_mds_listen_port }} __ANSIBLE_TEMPLATE__
# dummy server port
mds.dummy.port=7700  # __CURVEADM_TEMPLATE__ ${service_dummy_port} __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ {{ curvefs_mds_listen_dummy_port }} __ANSIBLE_TEMPLATE__
mds.common.logDir=/tmp/curvefs/mds  # __CURVEADM_TEMPLATE__ ${prefix}/logs __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ /tmp/{{ inventory_hostname }}/curvefs/mds __ANSIBLE_TEMPLATE__
#
# space options
#
space.addr=127.0.0.1:19999  # __ANSIBLE_TEMPLATE__ {{ groups.space | join_peer(hostvars, "space_listen_port") }} __ANSIBLE_TEMPLATE__
space.rpcTimeoutMs=500

#
# metaserver options
#
metaserver.addr=127.0.0.1:6701  # __CURVEADM_TEMPLATE__ ${cluster_mds_addr} __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ {{ groups.metaserver | join_peer(hostvars, "metaserver_listen_port") }} __ANSIBLE_TEMPLATE__
metaserver.rpcTimeoutMs=5000
metaserver.rpcRertyTimes=3
metaserver.rpcRetryIntervalUs=1000000

#
# etcd options
#
# etcd listen address
etcd.endpoint=127.0.0.1:2379  # __CURVEADM_TEMPLATE__ ${cluster_etcd_addr} __CURVEADM_TEMPLATE__  __ANSIBLE_TEMPLATE__ {{ groups.etcd | join_peer(hostvars, "etcd_listen_client_port") }} __ANSIBLE_TEMPLATE__
# timeout for establishing a connection
etcd.dailtimeoutMs=5000
# timeout for the operation
etcd.operation.timeoutMs=5000
# number of times a failed operation can be retried
etcd.retry.times=3

#
# leader election options
#
leader.sessionInterSec=5
leader.electionTimeoutMs=0

#
# topology config
#
# time interval flush data to db
mds.topology.TopologyUpdateToRepoSec=60
# the policy of choose pool 0:Random, 1:Weight
mds.topology.ChoosePoolPolicy=0
# partition number in each copyset 2^8
mds.topology.PartitionNumberInCopyset=256
# id number in each partition 2^24 [0, 2^24-1]
mds.topology.IdNumberInPartition=16777216
# create copyset number at a time
mds.topology.CreateCopysetNumber=10
# default create partition number 3
mds.topology.CreatePartitionNumber=3
# Topology update metric interval
mds.topology.UpdateMetricIntervalSec=60

#
# heartbeat config
#
# heartbeat interval between metaserver and mds
mds.heartbeat.intervalMs=10000
# heartbeat miss time between metaserver and mds
mds.heartbeat.misstimeoutMs=30000
# heartbeat offline time between metaserver and mds
mds.heartbeat.offlinetimeoutMs=1800000
# After mds is started, a certain time delay starts to guide the metaserver to delete data
# default is 20 min
mds.heartbeat.clean_follower_afterMs=1200000

#
# schedule config
#
# recoverScheduler switch
mds.enable.recover.scheduler=true
# copysetScheduler switch
mds.enable.copyset.scheduler=true
# RecoverScheduler round interval, the unit is second
mds.recover.scheduler.intervalSec=5
# copysetScheduler round interval, the unit is second
mds.copyset.scheduler.intervalSec=5
# the percentage difference for copysetScheduler to
# determine whether resource balancing is required
# based on the difference in resource usage percent, default is 30%
mds.copyset.scheduler.balanceRatioPercent=30
# Concurrency of operator on each metaserver
mds.schduler.operator.concurrent=1
# transfer leader timeout, after the timeout, mds removes the operator from the memory
mds.schduler.transfer.limitSec=60
# remove a replica timeout, after the timeout, mds removes the operator from the memory
mds.scheduler.remove.limitSec=300
# add a replica timeout, after the timeout, mds removes the operator from the memory
mds.scheduler.add.limitSec=1800
# change the replica timeout, after the timeout, mds removes the operator from the memory
mds.scheduler.change.limitSec=1800
# metaserver can be used as target leader only after starting coolingTimeSec_, the unit is second
mds.scheduler.metaserver.cooling.timeSec=1800

#
# fsmananger config
#
# the backend thread check whether fs is able to delete,
# check partition of deleting fs is deleting
mds.fsmanager.backEndThreadRunInterSec=10
