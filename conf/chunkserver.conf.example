#
# Global settings
#
# log等级INFO=0/WARNING=1/ERROR=2/FATAL=3
global.ip=127.0.0.1
global.port=8200
global.subnet=127.0.0.0/24
global.enable_external_server=false
global.external_ip=127.0.0.1
global.external_subnet=127.0.0.0/24
# chunk大小，一般16MB
global.chunk_size=16777216
# chunk 元数据页大小，一般4KB
global.meta_page_size=4096
# clone chunk允许的最长location长度
global.location_limit=3000

#
# MDS settings
#
#支持mds多地址，以逗号分隔 127.0.0.1:6666,127.0.0.1:7777
mds.listen.addr=127.0.0.1:6666
# 向mds注册的最大重试次数
mds.register_retries=100
# 向mds注册的rpc超时时间，一般1000ms
mds.register_timeout=1000
# 向mds发送心跳的间隔，一般10s
mds.heartbeat_interval=10
# 向mds发送心跳的rpc超时间，一般1000ms
mds.heartbeat_timeout=5000

#
# Chunkserver settings
#
# chunkserver主目录
chunkserver.stor_uri=local://./0/
# chunkserver元数据文件
chunkserver.meta_uri=local://./0/chunkserver.dat
# disk类型
chunkserver.disk_type=nvme
# raft内部install snapshot带宽上限，一般20MB
chunkserver.snapshot_throttle_throughput_bytes=20971520
# check cycles是为了更精细的进行带宽控制，以snapshotThroughputBytes=100MB，
# check cycles=10为例，它可以保证每1/10秒的带宽是10MB，且不累积，例如第1个
# 1/10秒的带宽是10MB，但是就过期了，在第2个1/10秒依然只能用10MB的带宽，而
# 不是20MB的带宽
chunkserver.snapshot_throttle_check_cycles=4

#
# Testing purpose settings
#
test.create_testcopyset=false
test.testcopyset_poolid=666
test.testcopyset_copysetid=888888
test.testcopyset_conf=127.0.0.1:8200:0,127.0.0.1:8201:0,127.0.0.1:8202:0

#
# Copyset settings
#
# 是否检查任期，一般检查
copyset.check_term=true
# 是否关闭raft配置变更的服务，一般不关闭
copyset.disable_cli=false
copyset.log_applied_task=false
# raft选举超时时间，一般是5000ms
copyset.election_timeout_ms=1000
# raft打快照间隔，一般是1800s，也就是30分钟
copyset.snapshot_interval_s=1800
# add一个节点，add的节点首先以类似learner的角色拷贝数据
# 在跟leader差距catchup_margin个entry的时候，leader
# 会尝试将配置变更的entry进行提交(一般来说提交的entry肯定
# 会commit&apply，catchup_margin较小可以大概率确保learner
# 后续很快可以加入复制组
copyset.catchup_margin=1000
# copyset chunk数据目录
copyset.chunk_data_uri=local://./0/copysets
# raft wal log目录
copyset.raft_log_uri=local://./0/copysets
# raft元数据目录
copyset.raft_meta_uri=local://./0/copysets
# raft snapshot目录
copyset.raft_snapshot_uri=curve://./0/copysets
# copyset回收目录
copyset.recycler_uri=local://./0/recycler
copyset.max_inflight_requests=5000
# chunkserver启动时，copyset并发加载的阈值,为0则表示不做限制
copyset.load_concurrency=10
# 检查copyset是否加载完成出现异常时的最大重试次数
copyset.check_retrytimes=3
# 当前peer的applied_index与leader上的committed_index差距小于该值
# 则判定copyset已经加载完成
copyset.finishload_margin=2000
# 循环判定copyset是否加载完成的内部睡眠时间
copyset.check_loadmargin_interval_ms=1000

#
# Clone settings
#
# 禁止使用curveclient
clone.disable_curve_client=false
# 禁止使用s3adapter
clone.disable_s3_adapter=false
# 克隆的分片大小，一般1MB
clone.slice_size=1048576
# 读clone chunk时是否需要paste到本地
# 该配置对recover chunk请求类型无效
clone.enable_paste=false
# 克隆的线程数量
clone.thread_num=10
# 克隆的队列深度
clone.queue_depth=6000
# curve用户名
curve.root_username=root
# curve密码
curve.root_password=root_password
# client配置文件
curve.config_path=conf/cs_client.conf
# s3配置文件
s3.config_path=conf/s3.conf

#
# Local FileSystem settings
#
# 是否开启使用renameat2，ext4内核3.15以后开始支持
fs.enable_renameat2=true

#
# metrics settings
# true means on, false means off
#
metric.onoff=true

#
# Storage engine settings
#
storeng.sync_write=false

#
# QoS settings
#

#
# Concurrent apply module
# 并发模块写线程的并发度，一般是10
wconcurrentapply.size=10
# 并发模块写线程的队列深度
wconcurrentapply.queuedepth=1
# 并发模块读线程的并发度，一般是5
rconcurrentapply.size=5
# 并发模块读线程的队列深度
rconcurrentapply.queuedepth=1

#
# Chunkfile pool
#
# 是否开启从chunkfilepool获取chunk，一般是true
chunkfilepool.enable_get_chunk_from_pool=true
# chunkfilepool目录
chunkfilepool.chunk_file_pool_dir=./0/
# chunkfilepool meta文件路径
#chunkfilepool.meta_path=./chunkfilepool.meta
# chunkfilepool meta文件大小
chunkfilepool.cpmeta_file_size=4096
# chunkfilepool get chunk最大重试次数
chunkfilepool.retry_times=5

#
# WAL file pool
#
# walpool是否共用chunkfilepool，如果为true，则以下配置无效
walfilepool.use_chunk_file_pool=true
# 是否开启从walfilepool获取chunk，一般是true
walfilepool.enable_get_segment_from_pool=true
# walpool目录
walfilepool.file_pool_dir=./0/
# walpool meta文件路径
walfilepool.meta_path=./walfilepool.meta
# walpool meta文件大小
walfilepool.segment_size=8388608
# WAL metapage大小
walfilepool.metapage_size=4096
# WAL filepool 元数据文件大小
walfilepool.meta_file_size=4096
# WAL filepool get chunk最大重试次数
walfilepool.retry_times=5

#
# trash settings
#
# chunkserver回收数据彻底删除的过期时间
trash.expire_afterSec=300
# chunkserver检查回收数据过期时间的周期
trash.scan_periodSec=120

# common option
#
# chunkserver 日志存放文件夹
chunkserver.common.logDir=./
# 单元测试情况下
# chunkserver.common.logDir=./runlog/
