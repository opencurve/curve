#
# Global settings
#
# Log levels: INFO=0/WARNING=1/ERROR=2/FATAL=3
global.ip=127.0.0.1
global.port=8200
global.subnet=127.0.0.0/24
global.enable_external_server=false
global.external_ip=127.0.0.1
global.external_subnet=127.0.0.0/24
# Chunk size, typically 16MB
global.chunk_size=16777216
# Chunk metadata page size, typically 4KB
global.meta_page_size=4096
# Maximum length allowed for the location of a clone chunk
# chunk's block size, IO requests must align with it, supported value is |512| and |4096|
# it should consist with `block_size` in chunkfilepool.meta_path and `mds.volume.blockSize` in MDS's configurations
# for clone chunk and snapshot chunk, it's also the minimum granularity that each bit represents
# if set to |512|, we need 4096 bytes bitmap for each chunk, so meta_page_size should be 8192 or larger.
global.block_size=4096
global.location_limit=3000

#
# MDS settings
#
# Support for multiple addresses for MDS, separated by commas: 127.0.0.1:6666,127.0.0.1:7777
mds.listen.addr=127.0.0.1:6666
# Maximum retry count for registering with MDS
mds.register_retries=100
# RPC timeout for MDS registration, typically 1000ms
mds.register_timeout=1000
# Interval for sending heartbeats to MDS, usually 10s
mds.heartbeat_interval=10
# RPC timeout for sending heartbeats to MDS, typically 1000ms
mds.heartbeat_timeout=5000

#
# Chunkserver settings
#
# Main directory for chunkserver
chunkserver.stor_uri=local://./0/
# Metadata file for chunkserver
chunkserver.meta_uri=local://./0/chunkserver.dat
# Disk type
chunkserver.disk_type=nvme
# Raft internal install snapshot bandwidth limit, usually 20MB
chunkserver.snapshot_throttle_throughput_bytes=20971520
# Throttle check cycles are for finer-grained bandwidth control. For example,
# with snapshotThroughputBytes=100MB and check cycles=10, it ensures that
# the bandwidth is 10MB every 1/10 second, without accumulation. For instance,
# the bandwidth is 10MB for the first 1/10 second, but it expires after that.
# In the second 1/10 second, the bandwidth remains 10MB, not 20MB.
chunkserver.snapshot_throttle_check_cycles=4
# Limit for the number of inflight IO requests, usually 5000
chunkserver.max_inflight_requests=5000

#
# Testing purpose settings
#
test.create_testcopyset=false
test.testcopyset_poolid=666
test.testcopyset_copysetid=888888
test.testcopyset_conf=127.0.0.1:8200:0,127.0.0.1:8201:0,127.0.0.1:8202:0

#
# Copyset settings
#
# Whether to check the term, usually checked
copyset.check_term=true
# Whether to disable the service for raft configuration changes, generally not disabled
copyset.disable_cli=false
copyset.log_applied_task=false
# Raft election timeout, usually 5000ms
copyset.election_timeout_ms=1000
# Raft snapshot interval, usually 1800s, i.e., 30 minutes
copyset.snapshot_interval_s=1800
# When adding a node, the added node first copies data in a role similar to a learner.
# When there is a difference of catchup_margin entries from the leader, the leader
# will attempt to commit and apply the configuration change entry (usually the committed
# entry will certainly be committed and applied). A smaller catchup_margin can ensure
# that the learner can quickly join the replication group.
copyset.catchup_margin=1000
# Copyset chunk data directory
copyset.chunk_data_uri=local://./0/copysets
# Raft WAL log directory
copyset.raft_log_uri=curve://./0/copysets
# Raft metadata directory
copyset.raft_meta_uri=local://./0/copysets
# Raft snapshot directory
copyset.raft_snapshot_uri=curve://./0/copysets
# Copyset recycling directory
copyset.recycler_uri=local://./0/recycler
# When the chunk server starts, the threshold for concurrent loading of copysets, set to 0 to indicate no limitation.
copyset.load_concurrency=10
# Number of threads used by chunk server for copyset complete synchronization.
copyset.sync_concurrency=20
# Maximum retry times when checking for exceptions during copyset loading.
copyset.check_retrytimes=3
# If the difference between the applied_index of the current peer and the committed_index
# on the leader is less than this value, the copyset is considered loaded.
copyset.finishload_margin=2000
# Internal sleep time for cyclically determining if the copyset is loaded.
copyset.check_loadmargin_interval_ms=1000
# scan copyset interval
copyset.scan_interval_sec=5
# the size each scan 4MB
copyset.scan_size_byte=4194304
# the follower send scanmap to leader rpc timeout
copyset.scan_rpc_timeout_ms=1000
# the follower send scanmap to leader rpc retry times
copyset.scan_rpc_retry_times=3
# the follower send scanmap to leader rpc retry interval
copyset.scan_rpc_retry_interval_us=100000
# enable O_DSYNC when open chunkfile
copyset.enable_odsync_when_open_chunkfile=true
# sync trigger seconds
copyset.sync_trigger_seconds=25
# sync chunk limit default = 2MB
copyset.sync_chunk_limits=2097152
# 30s if the sum of write > sync_threshold, let the sync_chunk_limits doubled.
copyset.sync_threshold=65536
# check syncing interval
copyset.check_syncing_interval_ms=500

#
# Clone settings
#
# Prohibit the use of curveclient
clone.disable_curve_client=false
# Prohibit the use of s3adapter
clone.disable_s3_adapter=false
# The shard size of the clone, usually 1MB
clone.slice_size=1048576
# Do I need to paste to the local location when reading the clone chunk
# This configuration is not valid for the recover chunk request type
clone.enable_paste=false
# Number of cloned threads
clone.thread_num=10
# Queue depth for cloning
clone.queue_depth=6000
# Curve username
curve.root_username=root
# Curve password
curve.root_password=root_password
# Client configuration file
curve.config_path=conf/cs_client.conf
# S3 configuration file
s3.config_path=conf/s3.conf
# Curve File time to live
curve.curve_file_timeout_s=30

#
# Local FileSystem settings
#
# Whether to enable the use of renameat2, ext4 kernel support starting from 3.15 onwards
fs.enable_renameat2=true

#
# metrics settings
# true means on, false means off
#
metric.onoff=true

#
# Storage engine settings
#
storeng.sync_write=false

#
# QoS settings
#

#
# Concurrent apply module
# The concurrency of concurrent module writing threads is generally 10
wconcurrentapply.size=10
# Queue depth of concurrent module write threads
wconcurrentapply.queuedepth=1
# The concurrency of concurrent module read threads is generally 5
rconcurrentapply.size=5
# Queue depth of concurrent module read threads
rconcurrentapply.queuedepth=1

#
# Chunkfile pool
#
# Whether to enable obtaining chunks from chunkfilepool, usually true
chunkfilepool.enable_get_chunk_from_pool=true
# chunkfilepool directory
chunkfilepool.chunk_file_pool_dir=./0/chunks
# chunkfilepool meta file path
#chunkfilepool.meta_path=./chunkfilepool.meta
# chunkfilepool meta file size
chunkfilepool.cpmeta_file_size=4096
# chunkfilepool get chunk maximum retry count
chunkfilepool.retry_times=5
# Enable clean chunk
chunkfilepool.clean.enable=true
# The bytes per write for cleaning chunk (max: 1MB)
chunkfilepool.clean.bytes_per_write=4096
# The throttle iops for cleaning chunk (4KB/IO)
chunkfilepool.clean.throttle_iops=500
# Whether allocate filePool by percent of disk size.
chunkfilepool.allocated_by_percent=true
# Preallocate storage percent of total disk
chunkfilepool.allocate_percent=80
# Preallocate storage size of chunkfilepool (None/KB/MB/GB/TB)
chunkfilepool.chunk_file_pool_size=1GB
# The thread num for format chunks
chunkfilepool.thread_num=1

#
# WAL file pool
#
# Does walpool share chunkfilepool? If true, the configuration is invalid starting from the third entry
walfilepool.use_chunk_file_pool=true
# Enable when WALpool and ChunkFilePool are shared, and reserve space for WALpool during capacity allocation
walfilepool.use_chunk_file_pool_reserve=15
# Whether to enable obtaining chunks from walfilepool, usually true
walfilepool.enable_get_segment_from_pool=true
# Walpool directory
walfilepool.file_pool_dir=./0/
# Walpool Meta File Path
walfilepool.meta_path=./walfilepool.meta
# Walpool Meta File Size
walfilepool.segment_size=8388608
# WAL metapage size
walfilepool.metapage_size=4096
# WAL filepool metadata file size
walfilepool.meta_file_size=4096
# WAL filepool get chunk maximum retry count
walfilepool.retry_times=5
# Whether allocate filePool by percent of disk size.
walfilepool.allocated_by_percent=true
# Preallocate storage percent of total disk
walfilepool.allocate_percent=10
# Preallocate storage size size of walfilepool (None/KB/MB/GB/TB)
walfilepool.wal_file_pool_size=0
# The thread num for format chunks
walfilepool.thread_num=1

#
# trash settings
#
# The expiration time for chunkserver to completely delete data for recycling
trash.expire_afterSec=300
# Chunkserver checks the cycle of recycling data expiration time
trash.scan_periodSec=120

# common option
#
# Chunkserver log storage folder
chunkserver.common.logDir=./
# In the case of unit testing
# chunkserver.common.logDir=./runlog/
