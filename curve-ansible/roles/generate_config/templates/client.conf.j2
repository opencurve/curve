#
###################MDS side configuration information##################
#

#Address information for mds, separated by commas for mds clusters
{% set mds_address=[] -%}
{% for host in groups.mds -%}
  {% set mds_ip = hostvars[host].ansible_ssh_host -%}
  {% set mds_port = hostvars[host].mds_port -%}
  {% set _ = mds_address.append("%s:%s" % (mds_ip, mds_port)) -%}
{% endfor -%}
mds.listen.addr={{ mds_address | join(',') }}

#Register switch with mds during initialization phase, default to on
mds.registerToMDS={{ client_register_to_mds }}

#RPC timeout for communication with mds
mds.rpcTimeoutMS={{ client_mds_rpc_timeout_ms }}

#The maximum timeout for rpc communication with mds, and the timeout for exponential backoff cannot exceed this value
mds.maxRPCTimeoutMS={{ client_mds_max_rpc_timeout_ms }}

#Total retry time for communication with mds
mds.maxRetryMS={{ client_mds_max_retry_ms }}

#Switch if the number of consecutive retries on the current mds exceeds this limit, which includes the number of timeout retries
mds.maxFailedTimesBeforeChangeMDS={{ client_mds_max_failed_times_before_change_mds }}

#How many renewals are there within a lease period with MDS
mds.refreshTimesPerLease={{ client_mds_refresh_times_per_lease }}

#The mds RPC interface requires a period of sleep before each retry
mds.rpcRetryIntervalUS={{ client_mds_rpc_retry_interval_us }}

# The normal retry times for trigger wait strategy
mds.normalRetryTimesBeforeTriggerWait={{ client_mds_normal_retry_times_before_trigger_wait }}

# Max retry time for IO-Path request (milliseconds)
mds.maxRetryMsInIOPath={{ client_mds_max_retry_ms_in_io_path }}

# Sleep interval for wait (milliseconds)
mds.waitSleepMs={{ client_mds_wait_sleep_ms }}

#
#################Metacache Configuration Information################
#

#Obtain the rpc timeout of the leader
metacache.getLeaderTimeOutMS={{ client_metacache_get_leader_timeout_ms }}

#Retrieve the number of retries for the leader
metacache.getLeaderRetry={{ client_metacache_get_leader_retry }}

#Obtaining the leader interface requires a period of sleep before each retry
metacache.rpcRetryIntervalUS={{ client_metacache_rpc_retry_interval_us }}

#
###############Configuration information of the scheduling layer#############
#

#Scheduling layer queue size, with one queue for each file
#The depth of the scheduling queue can affect the overall throughput of the client, as it stores asynchronous IO tasks..
schedule.queueCapacity={{ client_schedule_queue_capacity }}

#Number of execution threads in the queue
#What the executing thread needs to do is to retrieve the IO, then send it to the network and return to retrieve the next network task. A task starts from
#The RPC request is approximately (20us-100us) from the time the queue is retrieved to the time it is sent, and 20us is the normal time when it is not necessary to obtain a leader
#If a leader needs to be obtained during sending, the time will be around 100us, and the throughput of one thread will be between 10w-50w
#The performance has met the requirements
schedule.threadpoolSize={{ client_schedule_threadpool_size }}

#To isolate the task queue introduced by the QEMU side thread, as there is only one IO thread on the QEMU side
#When the QEMU side calls the AIO interface, it directly pushes the call to the task queue and returns,
#This way, libcurve does not occupy QEMU's threads and does not block its asynchronous calls
isolation.taskQueueCapacity={{ client_isolation_task_queue_capacity }}

#The size of the task queue thread pool for isolating QEMU threads, with a default value of 1 thread
isolation.taskThreadPoolSize={{ client_isolation_task_thread_pool_size }}


#
################Configuration related to communication with chunkserver#############
#
#Retrying sleep between OPs with failed read/write interfaces
chunkserver.opRetryIntervalUS={{ client_chunkserver_op_retry_interval_us }}

#Number of failed OP retries
chunkserver.opMaxRetry={{ client_chunkserver_op_max_retry }}

#RPC timeout for communication with chunkserver
chunkserver.rpcTimeoutMS={{ client_chunkserver_rpc_timeout_ms }}

#Enable reading based on appliedindex for performance optimization
chunkserver.enableAppliedIndexRead={{ client_chunkserver_enable_applied_index_read }}

#Maximum sleep time between retry requests
#Because when the network is congested or the chunkserver is overloaded, it is necessary to increase sleep time
#The maximum time for this is maxRetrySleepIntervalUs
chunkserver.maxRetrySleepIntervalUS={{ client_chunkserver_max_retry_sleep_interval_us }}

#The maximum timeout rpc time for retry requests, which follows an exponential backoff strategy
#Because timeout occurs when the network is congested, it is necessary to increase the RPC timeout time
#The maximum time for this is maxTimeoutMS
chunkserver.maxRPCTimeoutMS={{ client_chunkserver_max_rpc_timeout_ms }}

#Maximum number of consecutive timeouts for the same chunkserver
#If this value is exceeded, a health check will be conducted, and if the health check fails, it will be marked as unstable
chunkserver.maxStableTimeoutTimes={{ client_chunkserver_max_stable_timeout_times }}
#The timeout of health check requests after consecutive RPC timeouts on chunkserver
chunkserver.checkHealthTimeoutMs={{ client_chunkserver_check_health_timeout_ms }}
#After the number of unstable chunkservers on the same server exceeds this value
#All chunkservers will be marked as unstable
chunkserver.serverStableThreshold={{ client_chunkserver_server_stable_threshold }}

#When the underlying chunkserver is under high pressure, unstable may also be triggered
#Due to copyset leader may change, the request timeout time will be set to the default value, resulting in IO hang
#In the case of real downtime, the request will be processed after a certain number of retries
#If you keep trying again, it's not a downtime situation, and at this point, the timeout still needs to enter the exponential backoff logic
#When the number of retries for a request exceeds this value, its timeout must enter exponential backoff
chunkserver.minRetryTimesForceTimeoutBackoff={{ client_chunkserver_min_retry_times_force_timeout_backoff }}

#When an RPC retry exceeds maxRetryTimesBeforeConsiderSuspend
#Record as suspended IO, metric will alarm
chunkserver.maxRetryTimesBeforeConsiderSuspend={{ client_chunkserver_max_retry_times_before_consider_suspend }}

#
#################File level configuration items#############
#
#Libcurve allows for the maximum number of unreturned rpcs in the underlying rpc scheduling, with each file's inflight RPC being independent
global.fileMaxInFlightRPCNum={{ client_file_max_inflight_rpc_num }}

#The maximum sharding KB for file IO distribution to the underlying chunkserver
global.fileIOSplitMaxSizeKB={{ client_file_io_split_max_size_kb }}

#
#################Log related configuration###############
#
#Log level INFO=0/WARNING=1/ERROR=2/FATAL=3
global.logLevel={{ client_log_level }}
#Set the path of the log
global.logPath={{ client_log_path }}
#In the case of unit testing
# logpath=./runlog/

#
################# read from source conf ###############
#
# close timeout fd which read from source file
closefd.timeout={{ client_closefd_timeout_sec }}
# timeInterval of backend thread iterates the fdMap to close the timeout fd
closefd.timeInterval={{ client_closefd_time_interval_sec }}

#
###############Metric configuration information#############
#
global.metricDummyServerStartPort={{ client_metric_dummy_server_start_port }}

#Whether to turn off health check: true/turn off false/do not turn off
global.turnOffHealthCheck={{ client_turn_off_health_check }}

#
#Session map file, storing the mapping from filename to path of the opened file
#
global.sessionMapPath={{ client_session_map_path }}

#
### throttle config
#
throttle.enable={{ client_throttle_enable }}

##### discard configurations #####
# enable/disable discard
discard.enable={{ client_discard_enable }}
# discard granularity
discard.granularity={{ client_discard_granularity }}
# discard cleanup task delay times in millisecond
discard.taskDelayMs={{ client_discard_task_delay_ms }}
