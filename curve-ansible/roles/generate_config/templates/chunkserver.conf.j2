#
# Global settings
#
#Log level INFO=0/WARNING=1/ERROR=2/FATAL=3
global.ip={{ ansible_ssh_host }}
global.port={{ chunkserver_base_port }}
global.subnet={{ chunkserver_subnet }}
global.enable_external_server={{ chunkserver_enable_external_server }}
global.external_ip={{ ansible_ssh_host }}
global.external_subnet={{ chunkserver_external_subnet }}
#Chunk size, usually 16MB
global.chunk_size={{ chunk_size }}
#Chunk metadata page size, usually 4KB
global.meta_page_size={{ chunkserver_meta_page_size }}
#The maximum allowed location length for clone chunks
global.location_limit={{ chunkserver_location_limit }}

#
# MDS settings
#
#Supports MDS multiple addresses, separated by commas 127.0.0.1:6666,127.0.0.1:7777
{% set mds_address=[] -%}
{% for host in groups.mds -%}
  {% set mds_ip = hostvars[host].ansible_ssh_host -%}
  {% set mds_port = hostvars[host].mds_port -%}
  {% set _ = mds_address.append("%s:%s" % (mds_ip, mds_port)) -%}
{% endfor -%}
mds.listen.addr={{ mds_address | join(',') }}
#Maximum number of retries registered with mds
mds.register_retries={{ chunkserver_register_retries }}
#RPC timeout for registering with mds, typically 1000ms
mds.register_timeout={{ chunkserver_register_timeout }}
#The interval between sending heartbeat to MDS, usually 10s
mds.heartbeat_interval={{ chunkserver_heartbeat_interval }}
#Send rpc timeout of heartbeat to mds, usually 1000ms
mds.heartbeat_timeout={{ chunkserver_heartbeat_timeout }}

#
# Chunkserver settings
#
#Chunkserver home directory
chunkserver.stor_uri={{ chunkserver_stor_uri }}
#Chunkserver metadata file
chunkserver.meta_uri={{ chunkserver_meta_uri }}
#Disk type
chunkserver.disk_type={{ chunkserver_disk_type }}
#Raft internal install snapshot bandwidth limit, usually 20MB
chunkserver.snapshot_throttle_throughput_bytes={{ chunkserver_snapshot_throttle_throughput_bytes }}
#Check cycles are used for more precise bandwidth control, with snapshots ThroughputBytes=100MB,
#Taking check cycles=10 as an example, it can ensure that the bandwidth is 10MB every 1/10 second and does not accumulate, such as the first one
#The bandwidth of 1/10 second is 10MB, but it expires. In the second 1/10 second, only 10MB of bandwidth can be used, and
#Not a bandwidth of 20MB
chunkserver.snapshot_throttle_check_cycles={{ chunkserver_snapshot_throttle_check_cycles }}
chunkserver.max_inflight_requests={{ chunkserver_max_inflight_requests }}

#
# Testing purpose settings
#
test.create_testcopyset={{ chunkserver_test_create_testcopyset }}
test.testcopyset_poolid={{ chunkserver_test_testcopyset_poolid }}
test.testcopyset_copysetid={{ chunkserver_test_testcopyset_copysetid }}
test.testcopyset_conf={{ chunkserver_test_testcopyset_conf }}

#
# Copyset settings
#
#Whether to check the term of office, general inspection
copyset.check_term={{ chunkserver_copyset_check_term }}
#Do you want to close the service for raft configuration changes? Generally, it is not closed
copyset.disable_cli={{ chunkserver_copyset_disable_cli }}
copyset.log_applied_task={{ chunkserver_copyset_log_applied_task }}
#Raft election timeout, usually 5000ms
copyset.election_timeout_ms={{ chunkserver_copyset_election_timeout_ms }}
#The snapshot interval for the raft is usually 1800s, which is 30 minutes
copyset.snapshot_interval_s={{ chunkserver_copyset_snapshot_interval_s }}
# Add a node. The node added by 'add' first copies data in a way similar to a learner.
# When the difference from the leader reaches 'catchup_margin' entries,
# the leader will attempt to commit the configuration-changing entry.
# Generally, the committed and applied entry will definitely be committed and applied.
# A smaller catchup_margin can significantly ensure that the learner can quickly join the replication group soon after.
copyset.catchup_margin={{ chunkserver_copyset_catchup_margin }}
#Copyset chunk data directory
copyset.chunk_data_uri={{ chunkserver_copyset_chunk_data_uri }}
#Raft wal log directory
copyset.raft_log_uri={{ chunkserver_copyset_raft_log_uri }}
#Raft metadata directory
copyset.raft_meta_uri={{ chunkserver_copyset_raft_meta_uri }}
#Raft snapshot directory
copyset.raft_snapshot_uri={{ chunkserver_copyset_raft_snapshot_uri }}
#Copyset Recycle Directory
copyset.recycler_uri={{ chunkserver_copyset_recycler_uri }}
#When chunkserver is started, the threshold for copyset concurrent loading is set to 0, indicating no restrictions are imposed
copyset.load_concurrency={{ chunkserver_copyset_load_concurrency }}
#Check if the copyset has completed loading and the maximum number of retries when an exception occurs
copyset.check_retrytimes={{ chunkserver_copyset_check_retrytimes }}
#The difference between the applied_index of the current peer and the committed_index on the leader is less than this value.
#Then it is determined that the copyset has been loaded successfully
copyset.finishload_margin={{ chunkserver_copyset_finishload_margin }}
#Internal sleep time for loop determination of whether copyset has been loaded and completed
copyset.check_loadmargin_interval_ms={{ chunkserver_copyset_check_loadmargin_interval_ms }}
# scan copyset interval
copyset.scan_interval_sec={{ chunkserver_copyset_scan_interval_sec }}
# the size each scan 4MB
copyset.scan_size_byte={{ chunkserver_copyset_scan_size_byte }}
# the follower send scanmap to leader rpc timeout
copyset.scan_rpc_timeout_ms={{ chunkserver_copyset_scan_rpc_timeout_ms }}
# the follower send scanmap to leader rpc retry times
copyset.scan_rpc_retry_times={{ chunkserver_copyset_scan_rpc_retry_times }}
# the follower send scanmap to leader rpc retry interval
copyset.scan_rpc_retry_interval_us={{ chunkserver_copyset_scan_rpc_retry_interval_us }}
copyset.enable_odsync_when_open_chunkfile={{ chunkserver_copyset_enable_odsync_when_open_chunkfile }}
copyset.synctimer_interval_ms={{ chunkserver_copyset_synctimer_interval_ms }}
copyset.check_syncing_interval_ms={{ chunkserver_copyset_check_syncing_interval_ms }}

#
# Clone settings
#
#Prohibit the use of curveclient
clone.disable_curve_client={{ disable_snapshot_clone }}
#Prohibit the use of s3adapter
clone.disable_s3_adapter={{ disable_snapshot_clone }}
#The shard size of the clone, usually 1MB
clone.slice_size={{ chunkserver_clone_slice_size }}
#Do I need to paste to the local location when reading the clone chunk
#This configuration is not valid for the recover chunk request type
clone.enable_paste={{ chunkserver_clone_enable_paste }}
#Number of cloned threads
clone.thread_num={{ chunkserver_clone_thread_num }}
#Queue depth for cloning
clone.queue_depth={{ chunkserver_clone_queue_depth }}
#Curve username
curve.root_username={{ curve_root_username }}
#Curve password
curve.root_password={{ curve_root_password }}
#Client configuration file
curve.config_path={{ chunkserver_client_config_path }}
#S3 configuration file
s3.config_path={{ chunkserver_s3_config_path }}
# Curve File time to live
curve.curve_file_timeout_s={{ curve_file_timeout_s }}

#
# Local FileSystem settings
#
#Whether to enable the use of renameat2, ext4 kernel support starting from 3.15 onwards
fs.enable_renameat2={{ chunkserver_fs_enable_renameat2 }}

#
# metrics settings
# true means on, false means off
#
metric.onoff={{ chunkserver_metric_onoff }}

#
# Storage engine settings
#
storeng.sync_write={{ chunkserver_storeng_sync_write }}

#
# QoS settings
#

#
# Concurrent apply module
#
#The concurrency of concurrent modules is generally 10
wconcurrentapply.size={{ chunkserver_wconcurrentapply_size }}
#Queue depth of concurrent module threads
wconcurrentapply.queuedepth={{ chunkserver_wconcurrentapply_queuedepth }}
#The concurrency of concurrent module read threads is generally 5
rconcurrentapply.size={{ chunkserver_rconcurrentapply_size }}
#Queue depth of concurrent module read threads
rconcurrentapply.queuedepth={{ chunkserver_rconcurrentapply_queuedepth }}

#
# Chunkfile pool
#
#Whether to enable obtaining chunks from chunkfilepool, usually true
chunkfilepool.enable_get_chunk_from_pool={{ chunkserver_format_disk }}
#Chunkfilepool directory
chunkfilepool.chunk_file_pool_dir={{ chunkserver_chunkfilepool_chunk_file_pool_dir }}
#Chunkfilepool meta file path
#chunkfilepool.meta_path=./chunkfilepool.meta
#Chunkfilepool meta file size
chunkfilepool.cpmeta_file_size={{ chunkserver_chunkfilepool_cpmeta_file_size }}
#Chunkfilepool get chunk maximum retry count
chunkfilepool.retry_times=5
# Enable clean chunk
chunkfilepool.clean.enable={{ chunkserver_chunkfilepool_clean_enable }}
# The bytes per write for cleaning chunk (max: 1MB)
chunkfilepool.clean.bytes_per_write={{ chunkserver_chunkfilepool_clean_bytes_per_write }}
# The throttle iops for cleaning chunk (4KB/IO)
chunkfilepool.clean.throttle_iops={{ chunkserver_chunkfilepool_clean_throttle_iops }}

#
# WAL file pool
#
#Does walpool share chunkfilepool? If true, the following configuration is invalid
walfilepool.use_chunk_file_pool={{ walfilepool_use_chunk_file_pool }}
#Whether to enable obtaining chunks from waffilepool, usually true
walfilepool.enable_get_segment_from_pool={{ chunkserver_format_disk }}
#Walpool directory
walfilepool.file_pool_dir={{ chunkserver_walfilepool_file_pool_dir }}
#Walpool Meta File Path
walfilepool.meta_path={{ chunkserver_walfilepool_meta_path }}
#Walpool Meta File Size
walfilepool.segment_size={{ chunkserver_walfilepool_segment_size }}
#WAL metapage size
walfilepool.metapage_size={{ chunkserver_walfilepool_metapage_size }}
#WAL filepool metadata file size
walfilepool.meta_file_size={{ chunkserver_walfilepool_meta_file_size }}
#WAL filepool get chunk maximum retry count
walfilepool.retry_times={{ chunkserver_walfilepool_retry_times }}

#
# trash settings
#
#The expiration time for chunkserver to completely delete data for recycling
trash.expire_afterSec={{ chunkserver_trash_expire_after_sec }}
#Chunkserver checks the cycle of recycling data expiration time
trash.scan_periodSec={{ chunkserver_trash_scan_period_sec }}

# common option
#
#Chunkserver log storage folder
chunkserver.common.logDir={{ chunkserver_common_log_dir }}
#In the case of unit testing
# chunkserver.common.logDir=./runlog/
